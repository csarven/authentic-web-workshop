# Authentic Web mini-workshop series: Meeting 2, C2PA

[May 6, 2025](https://www.w3.org/events/meetings/8235290b-3029-4252-a962-9988b74cc862/) note updated zoom info 

[Reading Materials](https://github.com/w3c/authentic-web-workshop/issues/12)

[Link to Leonard's slides](https://www.dropbox.com/scl/fi/n1i5ji9balhykjninvcew/Content-Credentials-W3C.pdf?rlkey=39402g5enl8wa71kpz8mq9aqk\&st=0nqlysoj\&dl=0)

[Link to Brendan’s slides](https://www.dropbox.com/scl/fi/1hss9islmhviz2694zmyx/2025-05-06-IPTC-and-Media-Provenance-W3C-workshop.pdf?rlkey=icws3ct2ve5h8444pcytixgw7\&dl=0)

Video record: https://customer-0kix77mxh2zzzae0.cloudflarestream.com/0173c125bc51583a02f9f1998338d2b3/watch

Chat: irc.w3.org #CredWeb

Chair: Tzviya Siegman
Scribe: François Daoust

Present:

1. Tzviya Siegman (W3C)
2. Dominique Hazael-Massieux (W3C)
3. Leonard Rosenthol (Adobe & C2PA)
4. Ehsan Toreini (Samsung)
5. Scott Yates (trust.txt)
6. Brendan Quinn (IPTC)
7. Rose Newell (Independent / associated with Forward Democracy)
8. Chris Needham (BBC)
9. Judy Parnall (BBC)
10. Charlie Halford (BBC)
11. Bob Wyman
12. Barrett Golding ([Iffy.news](https://iffy.news/))
13. Go Ohtake
14. François Daoust (W3C)
15. [Sarven Capadisli](https://csarven.ca/#i) ( <https://dokie.li/> , W3C TAG )
16. Jeffrey Yasskin (Google Chrome)
17. Max Gendler
18. Daniel Appelquist (hats: Samsung / C2PA / W3C TAG)
19. Virginia Balseiro ( <https://dokie.li> )
20. Shigeya Suzuki ( Originator Profile / Keio )
21. Annette Greiner (Lawrence Berkeley National Lab)
22. Michiko Kuriyama (Originator Profile)
23. Gu Xiaojun (Huawei)
24. Rick Byers (Google Chrome)
25. Sandro Hawke
26. Vagner Vinz
27. Victor Lu
28. Diogo Cortiz
29. Eric Scouten (Adobe / CAWG)
30. Xueyuan Jia (W3C)
31. Brian Kardell (Igalia)
32. [TallTed // Ted Thibodeau Jr](https://github.com/TallTed) (he/him) ([OpenLink Software](https://openlinksw.com/)) 
33. [Tantek Çelik](https://tantek.com/) (Mozilla, Credweb CG) — for part of the meeting


Tzviya: [Sets the background and plan]

## C2PA
Presentation available at <https://www.dropbox.com/scl/fi/n1i5ji9balhykjninvcew/Content-Credentials-W3C.pdf?rlkey=39402g5enl8wa71kpz8mq9aqk&st=0nqlysoj&dl=0>

Leonard: For those who do not know me, I’m a senior principal architect at Adobe. I’m focusing on content authenticity. I chair the Technical Working Group of C2PA. My talk here is with my C2PA hat on, not on behalf of Adobe.

Leonard: Who is C2PA. I’m focusing on key pieces here. 11 steering committee members. Over 500 members total, including human right organizations, etc. Diverse constituencies.

Leonard: We are focused on provenance. About providing a set of information about digital content. We build a standard called C2PA providing this foundational technology for providing cryptographically verifiable and tamper-resistant provenance information. We just published version 2.2 last night. We have a completely revised explainer document, more aligned with W3C explainers. Lots of clarifications as well. The standard is currently in ballot on its way to become an ISO standard (ISO 22144).

Leonard: We’ve been doing this a while now. We started in 2019-2020. 2023 is what I call the year of the creators. Microsoft, Adobe, OpenAI, etc. started to integrate C2PA in their tools. Content created by AI now has markers to say that they were generated by AI. Hardware vendors also started to integrate C2PA. 2024 is the year of the consumers. TikTok, Meta, etc. consume the media and present it to end users. 2025 started very well with Samsung creating a smartphone that embeds C2PA natively. I’m going to present tomorrow to MOMA. Another example is microscopes where a lot of data gets captured by cameras with a publishing workflow all the way to research papers.

Leonard: A few key points. At its heart, a content credential a.k.a. A manifest, based on JUMBF, is a set of boxes, each of them containing assertions. There’s a whole fallback mechanism. These assertions include a claim, digitally signed. That’s on the left on the slide. On the right is an example. The UI is not mandatory in any way.

Leonard: Looking at an example from the BBC. They provide content credentials to many of their assets. This is showing you that it is coming from the BBC, a video with precise location information. Provenance can be human provenance, e.g., media forensics added by humans. All of that is contained in this content credential.

Leonard: The trust model is well aligned with the trust model on the web. We use the same signing model as TLS does. Rather than relying on the trust list that ships with browsers, we have our own trust list that focuses on our use cases. For example, if you’re in the EU, you may want to add a new one. But same model, series of trust anchors. We do have a few extra things because some hardware devices have trusted execution environments. And that is used by some vendors. We know the importance of timestamp trustworthiness but cannot be done offline. The idea of post-signing timestamps exists.

Leonard: We also have a model for soft binding. As we know, our normal use case is that the content provenance is embedded in the asset, but there are many systems that remove metadata, voluntarily or not. With watermarking, you can add information that is visible or invisible to an asset. We also support fingerprinting. The combination of the 3 gives your reliability across the chain. You can use a standardized API to retrieve the provenance information of an asset. The idea is that this API will be implemented by one or more services, potentially decentralized, not by us.

Leonard: I mentioned that C2PA can be embedded in many different formats. You can also have them on the side. We also do collections, e.g., for zip files. A recently introduced feature is multi-asset scenarios. For example, motion photo, or scenarios where there are multiple components to a single asset.

Leonard: About generative AI, that comes a lot, with a lot of policy going on around the world. We focus on 3 different areas: 1. Identify assets created by AI. It could also be by humans. We brought this idea of regions of interest leveraging W3C ideas. Text-based regions, audio regions, etc. For example, you can describe that just a part of an image was generated by AI. We also have use cases where regions of interest are used for other purpose than just for AI. It’s a very rich model.

Leonard: 2. The “recipe”. Anything that can be useful downstream to identify information about the asset or potentially re-create the asset. If you have all the information, you could perhaps re-create the asset entirely.

Leonard: 3. The final piece done by [CAWG](https://cawg.io) is to allow creators to label content with a “Do not train” flag. Done in collaboration with W3C TDM CG, and IETF. We’ve been partnering to make sure directions align across standards and standard bodies.

Leonard: Some more examples, on the left generated by AI, etc.

Leonard: One of the first things that went live was this joined project by TruePic and Microsoft when they sent people across Ukraine, to collect data for the Project Provenance that is still online. A good example of how an NGO can leverage the technology.

Leonard: Another example from a group from the national department of defense to provide images with content provenance information as part of it, published on their website. There are lots of others that are producing similar sites. Here, it’s a Wordpress website that leverages a library called C2PA Tool to gather and display the C2PA information. C2PA had nothing to do with this, and that’s great!

Leonard: Lots of implementation. dash.js is an example for support on media. That’s just the tip of the iceberg. You will see more every day. The adoption of the standard is our goal.

Leonard: What’s next? We recently started a group on commercial audio solutions, led by someone from Universal Music Group, live video, led by a team working on Youtube. Another one is the Text task force, including HTML. And then we’re in the process of rewriting our UX guidance. People want general philosophical directions.

Leonard: I mentioned CAWG, they are part of DIF, focused entirely on identity. That’s the core extension they bring to C2PA. They are also focused on metadata.

Leonard: The other group I want to mention to connect the dots is the ISO JPEG committee. They publish JPEG TRUST, ISO 21617. They are revising it. They’re connecting 4 key dots: CAWG identity connected to metadata (to describe the role) and then, building on W3C RIF how you define a set of rights and reservations on usage. For example, “if you want to use that video, pay me a few dollars”.

Leonard: The example in this slide shows how we connect things together. Metadata leverages Dublin Core, connected to the CAWG identity, verifiable identities, rights, all of this interchangeable using URIs.

Leonard: That’s the 10,000 foot introduction with hints about upcoming steps.

Brendan: We, at IPTC, have extended C2PA somewhat to bring it to the news industry. IPTC is a trade body where we set technical standards for the news industry to exchange news information, including things such as W3C ODRL. Wide breath of members: Image libraries, content providers, news publishers, news agencies, etc.

Brendan: Why we’re interested in this area. We have a strong history in photo/video metadata, we’ve been working with Adobe for some time, used by professional photographers, etc. around the world. Secure provenance solutions is the next step.

Brendan: You heard a lot about C2PA. To broaden a little bit, there’s the content authenticity initiative, with people looking at solutions in that space. That eventually led to C2PA. IPTC adopted this. Project Origin had existed for a while and we were working with them for some time. The work is now being carried out under the auspices of IPTC.

Brendan: We are focusing on identifying who published a piece of content. That’s our main goal. Miscontextualized images and video files where people would take some artwork and share around and re-publish it pretending that it’s related to some news. There are many ways that publishers can add metadata around content, adding verifying information to give consumers that extra level of awareness and security.

Brendan: 3 workflows for C2PA from the news perspective. In the long term, we hope there will be one: the glass-to-glass workflow, where each step along the way can be verified. But we know this will take time. We’re looking at a workflow where the publisher stamps the content on its way out. That’s not the same level of information as in the glass-to-glass workflow, but at least you get some identity information, and then you can better support scenarios where you need to redact content for example to blur a child’s face according to law. And then another workflow with stamping on the way in on top of on the way out.

Brendan: We created an additional trust list. Separately maintained IPTC list. The publishers themselves with vetted organization certificates. People can buy these certificates from official certificate authorities. We add their certificate to the list and that list can be adopted by the tools to check that the identity that signed the stamp was part of the trust list.

Brendan: We’re in phase 1 stage. Around 50 organizations. Around 20-30 publishers by mid-2025. Mainly people testing the waters for now to gather feedback. For phase 2, we are looking to make this more scalable, and looking for the browser's PKI as a guide, with intermediate certificates.

Brendan: It’s quite straightforward for a news organization to get a certificate. About $300 to get one. Then we have a very simple onboarding process, especially for members of IPTC.

Brendan: And then there are tools to start signing your content. We’re also working to get a common set of standardized metadata adopted. For our content, mostly it does not have ingredients. But you want to go back to underlying contexts.

Brendan: We also created a Wordpress tool that we use to sign all the content that we publish.

Brendan: UX studies include one from the BBC. Generally, the sign is positive. In some areas, there’s a bit of mixed signals, but that mostly boils down to the UX. There’s a big education piece to be done there. We are hopeful that, working together with our community, we will make it clearer what the tools can achieve and what they are for.

Brendan: We have a series of workshops this year. What we’re asking from W3C and from this group today is that we really want to get some ideas and feedback on how this can be more ingrained in the web platform. Some sort of API to access the information. Support in browsers would be useful as well.


## Questions and answers

Tzviya: First question from Jeffrey Yasskin about cameras, and whether keys got extracted and leaked from existing devices.

Leonard: The answer is no. They have not. There have been attempts. Somebody claimed that they accessed the keys on a device, but that turned out to be something else. So, no. Not at this time.

Dom: Building on that, how would you deal with such a situation? When a key leaks?

Leonard: It depends. We don’t mandate how individual hardware vendors manage their keys. Some of them rely on short-lived keys and key rotation. Others rely on intermediate CAs. Different approaches. If a vendor used one key which they put on every device, that would surely be bad. No one does that. It’s very device and implementation dependent. One of the differences between us and the Web for certificates is that we only care about the certificates at the time of signing. It doesn’t matter if a certificate gets revoked after having signed an asset. We have a revocation mechanism. We only care about whether the certificate was valid at the time of signing.

Jeffrey: When you’re verifying a C2PA signature, it has to be valid when you check it. If you have a second signature that also signed the content, you always need to trust some signature at the time of the verification.

Leonard: we see provenance as a tree or a graph; there is current verification. We also rely on the next signer doing a verification, building up the verification state throughout provenance. It's not only the latest that impact the validity and trust states. A challenge is how do you explain this to the end user if there is an invalid signature up in the chain, through what UX.

Rick: with regard to the security of the system and the physics of it; if C2PA is successful, wouldn't an attacker simply project an image onto a secure device?

Leonard: this is all about trust — if you trust the source, it doesn't matter: if I have a piece of content from the BBC where no one questions it's coming from there. I show it to one group who trust the BBC, another one doesn't — it's all about trust, not about cryptography and maths.

Rick: I don't really care about the reputation of a camera sensor, I do care about the reputation of the BBC

Leonard: there are use cases where this matters

Brendan:  Consider whether this can be used as another signal of whether the content is trustworthy or not

Rick: I agree the fundamental issue is about the flow of trust; do we think of this as a binary state (trusted/not trusted), vs a spectrum of how much trust to put into an organization you haven't encountered before

Leonard: the idea is to surface trust signals that end users can make use of to make their own assessment; this goes back to having the right UX to expose it

Brendan: we're looking at adding metadata on the publisher as a media organization, in addition to metadata on the asset itself; we don't want to make claims about whether an organization is trustworthy, but there are organizations that do that kind of assessment and auditing.

Brendan: Another signal we could add is trust signals from groups like the Trust Project or Journalism Trust Initiative

Tzvia: now questions around trust list and how they get maintained, with possible custom lists per communities

Leonard: the C2PA provides a trust list, the equivalent of the CA Browser Forum list; on top of that, there will be a variety of other ones from other industries, e.g., the IPTC one; multiple lists for different use cases and scenarios, e.g., we joke about having a car mechanic trust list. You could also have personalized trust lists maintained by the user. We're trying not to reinvent wheels if we can avoid it.

Dom: When I was at the IETF AI-Control workshop in September talking about using content for AI training, discussion about using certificates. Feedback from people involved in the CA/Browser forum is that this isn’t a model to follow. How confident are you that we can replicate something sufficiently reliable to support authenticity, especially when end users are exposed to these questions themselves?

Leonard: the C2PA trust model is rooted on the X501.9 certificate that has signed everything I've shoved before, similar to how digital signatures for PDF are managed. That model works for the outer trust model; that isn't to say that it necessarily works for humans and organizations involved in the process, which is where CAWG gets brought in.

Eric: The C2PA trust list focuses on signing by software and hardware components.CAWG has built a framework for different credential types; a framework of credential holders = descriptions of the assets (a subset of C2PA) + a signature from the credential holder, through a couple of ways. One targeted to institutional (esp media) allows x.509 certificates from organisations to be used in CAWG Identity Assertions to identify those organisations. Another is identity claims aggregation, for individual content creators who care about their social media accounts or their web sites where their audience knows them. This claim aggregation allows to build on the authentication of these systems to confirm the holder also controls the said account.

Tzviya: a good segue to the threat model questions

Leonard: We've done threat modeling through our "threats and harms" task force (dealing with both aspects separately). The threat area is co-chaired by security researchers from Adobe and Microsoft, and they focus on technical threats: e.g., metadata stripping, re-signing; how would someone attack our standard from a technical perspective. We try to maintain these threats to the best of our ability. Post-Quantum Crypto is on our radar (called out in our latest explainer). The Harms group is chaired by someone from Witness, a human rights organization, focused on harms to reputation, etc. Also constantly evolving, but e.g., what happens if a totalitarian regime requires a content credential associated with a specific name — a huge impact on privacy and personal security. A recent real world scenario: a country published a draft proposal standard for identifying content mandating the association of the creator's name to the content — we pushed back strongly against that idea, and it got removed from the latest version. Identity is important, but we don't want it to be mandated.

Tzviya: Let's move on to UX since you mentioned this as a critical issue. What user research have you done? Any idea around UI to expose this information?

Leonard: One of the earliest TF was the UX TF — they write UX guidelines, and serve as a sounding board for technical developments. THey have a sub-task force focused strictly on user research. The research is usually done by C2PA member orgs (not C2PA itself); the BBC, Adobe, Microsoft, Google have conducted studies over the existence of C2PA, with different focuses: terminology (e.g., does "provenance" work as a term), user experiences (what should you show, which led to the CR pin — something you can see quickly); we found various social web sites exposing it differently (LinkedIn with CR, Instagram with "made with AI") —we'll share the links to the studies. Done in the US and other countries/languages

Brendan: Another study is coming from IPTC that seems positive, expecting it to be published in a journal.

Leonard: when we started, we thought we wanted a uniform UI (à la padlock); it turns out not all implementers agree with that (e.g., for brand fitness), so we're restarting from a higher level concept approach. Including progressive disclosure through different levels (up to L3 which shows a full graph, L4 for forensics). We also thought "created by generative AI" was what was important to surface — it turns out 85% of users indicated they're interested in the reverse ("created by a human") — we're thinking through how to represent that, in particular in the context of hybrid content

Tzviya: for the remaining questions, let's continue the discussion on the github issue. Our next meeting is likely to be in June — let us know if you're interested in presenting there and then.

Leonard: Please reach out!
